{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a9ed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL: M1 (d=1), DISTRIBUTION: uniform\n",
      "======================================================================\n",
      "\n",
      "  n=100 (sample size 1/1):\n",
      "    Rep 1/1 | Elapsed: 9.9s | ETA for n=100: 0.0min | Total elapsed: 0.2min\n",
      "    BS (hat): Dim acc 1/1 (100%), Time(corr) 0.75±0.00s, SubErr(corr) 0.0000±0.0000, MinTime(corr) 0.3770±0.0000s, MinIters(corr) 20.0±0.0, TimePerIter(corr) 18.85±0.00ms, Time(all) 0.75±0.00s, SubErr(all) 0.0000±0.0000, MinTime(all) 0.3770±0.0000s, MinIters(all) 20.0±0.0, TimePerIter(all) 18.85±0.00ms\n",
      "    NW: Dim acc 1/1 (100%), Time(corr) 9.18±0.00s, SubErr(corr) 0.0365±0.0000, MinTime(corr) 4.5892±0.0000s, MinIters(corr) 93.5±0.0, TimePerIter(corr) 49.08±0.00ms, Time(all) 9.18±0.00s, SubErr(all) 0.0365±0.0000, MinTime(all) 4.5892±0.0000s, MinIters(all) 93.5±0.0, TimePerIter(all) 49.08±0.00ms\n",
      "\n",
      "All results saved to 'quick_test.csv'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import BSpline\n",
    "from scipy.linalg import lstsq, solve\n",
    "from scipy.optimize import minimize\n",
    "import argparse\n",
    "\n",
    "\n",
    "# ============== Kernels ==============\n",
    "\n",
    "def gaussian_kernel(u):\n",
    "    return np.exp(-0.5 * u**2) / np.sqrt(2 * np.pi)\n",
    "\n",
    "\n",
    "def fourth_order_kernel(u):\n",
    "    phi = np.exp(-0.5 * u**2) / np.sqrt(2 * np.pi)\n",
    "    return 0.5 * (3 - u**2) * phi\n",
    "\n",
    "\n",
    "def get_kernel(order=2):\n",
    "    if order == 4:\n",
    "        return fourth_order_kernel, 4\n",
    "    else:\n",
    "        return gaussian_kernel, 2\n",
    "\n",
    "\n",
    "def optimal_bandwidth_init(n, d, q=2):\n",
    "    return n ** (-1.0 / (2 * q + d))\n",
    "\n",
    "\n",
    "# ============== d=0 LOOCV (intercept only) ==============\n",
    "\n",
    "def loocv_d0(y):\n",
    "    \"\"\"\n",
    "    LOOCV for d=0 model: Y independent of X.\n",
    "    CV = (1/n) Σᵢ (Yᵢ - Ȳ₋ᵢ)² where Ȳ₋ᵢ is leave-one-out mean.\n",
    "    \n",
    "    Simplifies to: n/(n-1)² * Σᵢ (Yᵢ - Ȳ)²\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    y_bar = np.mean(y)\n",
    "    residuals = y - y_bar\n",
    "    cv = np.mean((n / (n - 1) * residuals) ** 2)\n",
    "    return cv\n",
    "\n",
    "\n",
    "# ============== B-spline basis ==============\n",
    "\n",
    "def compute_knots(x, n_knots, degree=3):\n",
    "    knot_positions = np.linspace(0, 100, n_knots + 2)[1:-1]\n",
    "    internal_knots = np.percentile(x, knot_positions)\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    return np.concatenate([\n",
    "        np.repeat(x_min, degree + 1),\n",
    "        internal_knots,\n",
    "        np.repeat(x_max, degree + 1)\n",
    "    ])\n",
    "\n",
    "\n",
    "def bspline_basis_1d(x, knots, degree=3):\n",
    "    return BSpline.design_matrix(x, knots, degree).toarray()\n",
    "\n",
    "\n",
    "def tensor_product_basis(X, knots_list, degree=3):\n",
    "    X = np.atleast_2d(X)\n",
    "    if X.shape[0] == 1:\n",
    "        X = X.T\n",
    "    n, p = X.shape\n",
    "    \n",
    "    basis = bspline_basis_1d(X[:, 0], knots_list[0], degree)\n",
    "    for j in range(1, p):\n",
    "        basis_j = bspline_basis_1d(X[:, j], knots_list[j], degree)\n",
    "        basis = np.einsum('ij,ik->ijk', basis, basis_j).reshape(n, -1)\n",
    "    \n",
    "    return basis\n",
    "\n",
    "\n",
    "def compute_knots_from_data(X, n_knots, degree=3):\n",
    "    X = np.atleast_2d(X)\n",
    "    if X.shape[0] == 1:\n",
    "        X = X.T\n",
    "    p = X.shape[1]\n",
    "    \n",
    "    if np.isscalar(n_knots):\n",
    "        n_knots = [n_knots] * p\n",
    "    \n",
    "    return [compute_knots(X[:, j], n_knots[j], degree) for j in range(p)]\n",
    "\n",
    "\n",
    "# ============== LOOCV methods ==============\n",
    "\n",
    "def bspline_loocv_hat(X, y, n_knots, degree=3):\n",
    "    X = np.atleast_2d(X)\n",
    "    if X.shape[0] == 1:\n",
    "        X = X.T\n",
    "    \n",
    "    knots_list = compute_knots_from_data(X, n_knots, degree)\n",
    "    B = tensor_product_basis(X, knots_list, degree)\n",
    "    \n",
    "    BtB = B.T @ B + 1e-10 * np.eye(B.shape[1])\n",
    "    Bty = B.T @ y\n",
    "    \n",
    "    coeffs = solve(BtB, Bty, assume_a='pos')\n",
    "    y_hat = B @ coeffs\n",
    "    \n",
    "    # Compute diagonal of hat matrix efficiently\n",
    "    X_solve = solve(BtB, B.T, assume_a='pos')  # Shape (k, n)\n",
    "    H_diag = np.einsum('ij,ji->i', B, X_solve)  # Diagonal of B @ X\n",
    "    \n",
    "    residuals = y - y_hat\n",
    "    loocv = np.mean((residuals / (1 - H_diag)) ** 2)\n",
    "    \n",
    "    return loocv\n",
    "\n",
    "\n",
    "def nw_loocv(X, y, bandwidth, kernel_order=4):\n",
    "    X = np.atleast_2d(X)\n",
    "    if X.shape[0] == 1:\n",
    "        X = X.T\n",
    "    n = len(y)\n",
    "    \n",
    "    kernel_fn, _ = get_kernel(kernel_order)\n",
    "    p = X.shape[1]\n",
    "    h = np.full(p, bandwidth) if np.isscalar(bandwidth) else np.asarray(bandwidth)\n",
    "    \n",
    "    squared_errors = []\n",
    "    for i in range(n):\n",
    "        u = (X[i, :] - X) / h\n",
    "        weights = np.prod(kernel_fn(u), axis=1)\n",
    "        weights[i] = 0\n",
    "        \n",
    "        w_sum = weights.sum()\n",
    "        if np.abs(w_sum) > 1e-10:\n",
    "            y_pred = (weights @ y) / w_sum\n",
    "        else:\n",
    "            y_pred = np.mean(np.delete(y, i))\n",
    "        \n",
    "        squared_errors.append((y[i] - y_pred) ** 2)\n",
    "    \n",
    "    return np.mean(squared_errors)\n",
    "\n",
    "\n",
    "# ============== Projection optimization ==============\n",
    "\n",
    "def make_beta(C, d, p):\n",
    "    C = C.reshape(p - d, d)\n",
    "    return np.vstack([np.eye(d), C])\n",
    "\n",
    "\n",
    "def projection_matrix(beta):\n",
    "    return beta @ np.linalg.solve(beta.T @ beta, beta.T)\n",
    "\n",
    "\n",
    "def subspace_distance(beta_true, beta_est):\n",
    "    \"\"\"\n",
    "    Compute Frobenius norm between projection matrices.\n",
    "    If beta_est is None (d=0), the estimated projection is the zero matrix.\n",
    "    \"\"\"\n",
    "    P_true = projection_matrix(beta_true)\n",
    "    \n",
    "    if beta_est is None:\n",
    "        # d_est = 0: projection onto trivial subspace is zero matrix\n",
    "        return np.linalg.norm(P_true, 'fro')\n",
    "    \n",
    "    P_est = projection_matrix(beta_est)\n",
    "    return np.linalg.norm(P_true - P_est, 'fro')\n",
    "\n",
    "\n",
    "def project_cv_bspline_hat(C, X, y, d, n_knots, degree):\n",
    "    n, p = X.shape\n",
    "    beta = make_beta(C, d, p)\n",
    "    X_proj = X @ beta\n",
    "    return bspline_loocv_hat(X_proj, y, n_knots, degree)\n",
    "\n",
    "\n",
    "def project_cv_nw(params, X, y, d, kernel_order):\n",
    "    n, p = X.shape\n",
    "    n_C = (p - d) * d\n",
    "    \n",
    "    C = params[:n_C]\n",
    "    h = np.exp(params[n_C])\n",
    "    \n",
    "    beta = make_beta(C, d, p)\n",
    "    X_proj = X @ beta\n",
    "    \n",
    "    return nw_loocv(X_proj, y, h, kernel_order)\n",
    "\n",
    "\n",
    "def optimize_bspline(X, y, d, n_knots, degree, method, n_restarts, rng):\n",
    "    \"\"\"Optimize projection for a fixed number of knots.\"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    if X.shape[0] == 1:\n",
    "        X = X.T\n",
    "    n, p = X.shape\n",
    "    \n",
    "    cv_fn = project_cv_bspline_hat\n",
    "    \n",
    "    # Track minimize stats\n",
    "    minimize_time_total = 0.0\n",
    "    minimize_count = 0\n",
    "    minimize_iters_total = 0\n",
    "    \n",
    "    if d >= p:\n",
    "        cv = bspline_loocv_hat(X, y, n_knots, degree)\n",
    "        return np.eye(p), cv, minimize_time_total, minimize_count, minimize_iters_total\n",
    "    \n",
    "    n_C = (p - d) * d\n",
    "    \n",
    "    best_cv = np.inf\n",
    "    best_beta = None\n",
    "    \n",
    "    for _ in range(n_restarts):\n",
    "        C0 = rng.standard_normal(n_C) * 0.1\n",
    "        \n",
    "        t_min_start = time.perf_counter()\n",
    "        res = minimize(\n",
    "            cv_fn, C0, args=(X, y, d, n_knots, degree),\n",
    "            method='CG', \n",
    "            options={'maxiter': 200, 'gtol': 1e-6}\n",
    "        )\n",
    "        minimize_time_total += time.perf_counter() - t_min_start\n",
    "        minimize_count += 1\n",
    "        minimize_iters_total += res.nit\n",
    "        \n",
    "        if res.fun < best_cv:\n",
    "            best_cv = res.fun\n",
    "            best_beta = make_beta(res.x, d, p)\n",
    "    \n",
    "    return best_beta, best_cv, minimize_time_total, minimize_count, minimize_iters_total\n",
    "\n",
    "\n",
    "def optimize_bspline_with_knots(X, y, d, degree, method, n_restarts, rng, model=None):\n",
    "    \"\"\"\n",
    "    Optimize projection AND number of knots jointly via grid search over knots.\n",
    "    \"\"\"\n",
    "    best_cv = np.inf\n",
    "    best_beta = None\n",
    "    best_n_knots = None\n",
    "    \n",
    "    # Track minimize stats across all knot candidates\n",
    "    total_minimize_time = 0.0\n",
    "    total_minimize_count = 0\n",
    "    total_minimize_iters = 0\n",
    "\n",
    "    n_knots = int(X.shape[0] ** (1 / (2*4 + d)))  # assuming 4 continuous derivatives\n",
    "    knot_candidates = [n_knots]\n",
    "    \n",
    "    for n_knots in knot_candidates:\n",
    "        knot_rng = np.random.default_rng(rng.integers(0, 2**31))\n",
    "        beta, cv, min_time, min_count, min_iters = optimize_bspline(X, y, d, n_knots, degree, method, n_restarts, knot_rng)\n",
    "        \n",
    "        total_minimize_time += min_time\n",
    "        total_minimize_count += min_count\n",
    "        total_minimize_iters += min_iters\n",
    "        \n",
    "        if cv < best_cv:\n",
    "            best_cv = cv\n",
    "            best_beta = beta\n",
    "            best_n_knots = n_knots\n",
    "    \n",
    "    return best_beta, best_cv, best_n_knots, total_minimize_time, total_minimize_count, total_minimize_iters\n",
    "\n",
    "\n",
    "def optimize_nw(X, y, d, kernel_order, n_restarts, rng):\n",
    "    X = np.atleast_2d(X)\n",
    "    if X.shape[0] == 1:\n",
    "        X = X.T\n",
    "    n, p = X.shape\n",
    "    \n",
    "    _, q = get_kernel(kernel_order)\n",
    "    h_init = optimal_bandwidth_init(n, d, q)\n",
    "    \n",
    "    # Track minimize stats\n",
    "    minimize_time_total = 0.0\n",
    "    minimize_count = 0\n",
    "    minimize_iters_total = 0\n",
    "    \n",
    "    if d >= p:\n",
    "        def cv_h(log_h):\n",
    "            return nw_loocv(X, y, np.exp(log_h), kernel_order)\n",
    "        \n",
    "        t_min_start = time.perf_counter()\n",
    "        res = minimize(cv_h, np.log(h_init), method='CG',\n",
    "                      options={'maxiter': 200, 'gtol': 1e-6})\n",
    "        minimize_time_total += time.perf_counter() - t_min_start\n",
    "        minimize_count += 1\n",
    "        minimize_iters_total += res.nit\n",
    "        \n",
    "        h_opt = np.exp(res.x[0])\n",
    "        cv = nw_loocv(X, y, h_opt, kernel_order)\n",
    "        return np.eye(p), h_opt, cv, minimize_time_total, minimize_count, minimize_iters_total\n",
    "    \n",
    "    n_C = (p - d) * d\n",
    "    \n",
    "    best_cv = np.inf\n",
    "    best_beta = None\n",
    "    best_h = None\n",
    "    \n",
    "    for _ in range(n_restarts):\n",
    "        C0 = rng.standard_normal(n_C) * 0.1\n",
    "        log_h0 = np.log(h_init) + rng.standard_normal() * 0.3\n",
    "        params0 = np.concatenate([C0, [log_h0]])\n",
    "        \n",
    "        t_min_start = time.perf_counter()\n",
    "        res = minimize(\n",
    "            project_cv_nw, params0, args=(X, y, d, kernel_order),\n",
    "            method='CG',\n",
    "            options={'maxiter': 200, 'gtol': 1e-6}\n",
    "        )\n",
    "        minimize_time_total += time.perf_counter() - t_min_start\n",
    "        minimize_count += 1\n",
    "        minimize_iters_total += res.nit\n",
    "        \n",
    "        if res.fun < best_cv:\n",
    "            best_cv = res.fun\n",
    "            best_beta = make_beta(res.x[:(p-d)*d], d, p)\n",
    "            best_h = np.exp(res.x[-1])\n",
    "    \n",
    "    return best_beta, best_h, best_cv, minimize_time_total, minimize_count, minimize_iters_total\n",
    "\n",
    "\n",
    "def search_dimension_single(X, y, max_d, degree, kernel_order, method, n_restarts, rng, model=None):\n",
    "    \"\"\"\n",
    "    Search for best dimension starting from d=0.\n",
    "    \"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    if X.shape[0] == 1:\n",
    "        X = X.T\n",
    "    n, p = X.shape\n",
    "    \n",
    "    best_cv = np.inf\n",
    "    best_d = None\n",
    "    best_beta = None\n",
    "    best_h = None\n",
    "    best_n_knots = None\n",
    "    cv_path = {}\n",
    "    \n",
    "    # Track minimize stats across all dimensions\n",
    "    total_minimize_time = 0.0\n",
    "    total_minimize_count = 0\n",
    "    total_minimize_iters = 0\n",
    "    \n",
    "    # Start with d=0 (intercept-only model)\n",
    "    cv_d0 = loocv_d0(y)\n",
    "    cv_path[0] = {'cv': cv_d0, 'n_knots': None, 'h': None}\n",
    "    best_cv = cv_d0\n",
    "    best_d = 0\n",
    "    best_beta = None\n",
    "    best_h = None\n",
    "    \n",
    "    # Search d=1, 2, ..., max_d\n",
    "    for d in range(1, min(max_d + 1, p)):\n",
    "        if method == 'hat':\n",
    "            beta, cv, n_knots, min_time, min_count, min_iters = optimize_bspline_with_knots(\n",
    "                X, y, d, degree, method, n_restarts, rng, model=model\n",
    "            )\n",
    "            cv_path[d] = {'cv': cv, 'n_knots': n_knots, 'h': None}\n",
    "            h = None\n",
    "        else:  # nw\n",
    "            beta, h, cv, min_time, min_count, min_iters = optimize_nw(X, y, d, kernel_order, n_restarts, rng)\n",
    "            cv_path[d] = {'cv': cv, 'n_knots': None, 'h': h}\n",
    "        \n",
    "        total_minimize_time += min_time\n",
    "        total_minimize_count += min_count\n",
    "        total_minimize_iters += min_iters\n",
    "        \n",
    "        if cv < best_cv:\n",
    "            best_cv = cv\n",
    "            best_d = d\n",
    "            best_beta = beta\n",
    "            best_h = h\n",
    "            if method == 'hat':\n",
    "                best_n_knots = n_knots\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return best_d, best_beta, best_h, best_cv, cv_path, total_minimize_time, total_minimize_count, total_minimize_iters\n",
    "\n",
    "\n",
    "# ============== Data generation ==============\n",
    " \n",
    "\n",
    "## True model structural dimensions\n",
    "MODEL_TO_DIM = {\n",
    "    'M1': 1, \n",
    "    'M2': 2, \n",
    "    'M3_func1': 3,\n",
    "    'M3_func2': 3\n",
    "}\n",
    "\n",
    "\n",
    "def generate_X(n, p, distribution, rng):\n",
    "    if distribution == 'uniform':\n",
    "        X = rng.uniform(0, 10, (n, p))\n",
    "    elif distribution == 'normal':\n",
    "        X = rng.standard_normal((n, p))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distribution: {distribution}\")\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def generate_data(n, p, model, distribution, sigma, rng):\n",
    "    \"\"\"\n",
    "    Generate data for a given model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str\n",
    "        One of 'M1', 'M2', 'M3_func1', 'M3_func2'\n",
    "    \"\"\"\n",
    "    X = generate_X(n, p, distribution, rng)\n",
    "    \n",
    "    if model == 'M1':\n",
    "        # y = z^3 + z^2 + z where z = β'X\n",
    "        d_true = 1\n",
    "        beta_true = np.zeros((p, 1))\n",
    "        beta_true[0, 0] = 1.0\n",
    "        beta_true[1, 0] = 1.0\n",
    "        beta_true[2, 0] = 1.0\n",
    "        beta_true[3, 0] = 1.0\n",
    "        \n",
    "        z = (X @ beta_true)[:, 0]\n",
    "        y = z**3 + z**2 + z\n",
    "        \n",
    "    elif model == 'M2':\n",
    "        # y = sin(x_1) * cos(2*x_2)\n",
    "        d_true = 2\n",
    "        beta_true = np.zeros((p, 2))\n",
    "        beta_true[0, 0] = 1.0\n",
    "        beta_true[1, 1] = 1.0\n",
    "        \n",
    "        z = X @ beta_true\n",
    "        y = np.sin(z[:, 0]) * np.cos(2*z[:, 1])\n",
    "        \n",
    "    elif model == 'M3_func1':\n",
    "        # y = 3*z_1^2 + 1.5*(cos(z_2) + sin(z_3))^2\n",
    "        d_true = 3\n",
    "        beta_true = np.zeros((p, 3))\n",
    "        beta_true[0, 0] = 1.0\n",
    "        beta_true[1, 1] = 1.0\n",
    "        beta_true[2, 2] = 1.0\n",
    "        \n",
    "        z = X @ beta_true\n",
    "        y = 3*z[:, 0]**2 + 1.5*(np.cos(z[:, 1]) + np.sin(z[:, 2]))**2\n",
    "        \n",
    "    elif model == 'M3_func2':\n",
    "        # Y = z_1/(0.25 + (z_2 + 1.5)^2) + 2*z_3^3 + ε with ε ~ N(0, sigma)\n",
    "\n",
    "        d_true = 3\n",
    "        beta_true = np.zeros((p, 3))\n",
    "        beta_true[0, 0] = 1.0\n",
    "        beta_true[1, 1] = 1.0\n",
    "        beta_true[2, 2] = 1.0\n",
    "        \n",
    "        z = X @ beta_true\n",
    "        y = z[:, 0] / (0.25 + (z[:, 1] + 1.5)**2) + 2*z[:, 2]**3\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"model must be 'M1', 'M2', 'M3_func1', or 'M3_func2', got {model}\")\n",
    "    \n",
    "    y += sigma * rng.standard_normal(n) # add noise\n",
    "    \n",
    "    return X, y, beta_true, d_true\n",
    "\n",
    "\n",
    "# ============== Experiment ==============\n",
    "\n",
    "def run_experiment_single(model, distribution, n_reps=100, p=10, degree=3, \n",
    "                          kernel_order=4, n_restarts=1, sigma=0.2, \n",
    "                          global_seed=42, output_file=None, method='all', sample_size=None):\n",
    "    \"\"\"\n",
    "    Run experiment for a single (model, distribution) combination.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str\n",
    "        One of 'M1', 'M2', 'M3_func1', 'M3_func2'\n",
    "    distribution : str\n",
    "        One of 'uniform', 'normal'\n",
    "    output_file : str, optional\n",
    "        CSV filename to save results\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        Results for this combination\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample sizes based on method\n",
    "    if method == 'hat':\n",
    "        sample_sizes_hat = [50, 100, 400, 1000, 2000, 5000]\n",
    "        sample_sizes_nw = []\n",
    "    elif method == 'nw':\n",
    "        sample_sizes_hat = []\n",
    "        sample_sizes_nw = [50, 100, 400, 1000, 2000, 5000]\n",
    "    else:  # 'all' - run both methods\n",
    "        sample_sizes_hat = [50, 100, 400, 1000, 2000, 5000]\n",
    "        sample_sizes_nw = [50, 100, 400, 1000, 2000, 5000]\n",
    "    \n",
    "    all_sample_sizes = sorted(set(sample_sizes_hat + sample_sizes_nw))\n",
    "    \n",
    "    # Filter to single sample size if specified\n",
    "    if sample_size is not None:\n",
    "        all_sample_sizes = [n for n in all_sample_sizes if n == sample_size]\n",
    "        sample_sizes_hat = [n for n in sample_sizes_hat if n == sample_size]\n",
    "        sample_sizes_nw = [n for n in sample_sizes_nw if n == sample_size]\n",
    "        if not all_sample_sizes:\n",
    "            raise ValueError(f\"Sample size {sample_size} not valid for method {method}\")\n",
    "    \n",
    "    # Pre-generate seeds for all possible sample sizes\n",
    "    all_possible_sample_sizes = [50, 100, 400, 1000, 2000, 5000]\n",
    "    \n",
    "    master_rng = np.random.default_rng(global_seed)\n",
    "    seeds = {}\n",
    "    for n in all_possible_sample_sizes:\n",
    "        for rep in range(n_reps):\n",
    "            seeds[(n, rep)] = master_rng.integers(0, 2**31)\n",
    "    \n",
    "    d_true = MODEL_TO_DIM[model]\n",
    "    max_d = d_true + 1\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"MODEL: {model} (d={d_true}), DISTRIBUTION: {distribution}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    results = []\n",
    "    total_start_time = time.perf_counter()\n",
    "    \n",
    "    for n_idx, n in enumerate(all_sample_sizes):\n",
    "        # Determine methods\n",
    "        methods_for_n = []\n",
    "        if n in sample_sizes_hat:\n",
    "            methods_for_n.append(('BS (hat)', 'hat'))\n",
    "        if n in sample_sizes_nw:\n",
    "            methods_for_n.append(('NW', 'nw'))\n",
    "        \n",
    "        # Initialize collectors\n",
    "        method_results = {}\n",
    "        for method_name, _ in methods_for_n:\n",
    "            method_results[method_name] = {\n",
    "                'times_all': [],\n",
    "                'times_correct': [],\n",
    "                'd_correct': 0,\n",
    "                'subspace_errors_all': [],\n",
    "                'subspace_errors': [],\n",
    "                'minimize_times_all': [],\n",
    "                'minimize_times_correct': [],\n",
    "                'minimize_counts_all': [],\n",
    "                'minimize_counts_correct': [],\n",
    "                'minimize_iters_all': [],\n",
    "                'minimize_iters_correct': []\n",
    "            }\n",
    "        \n",
    "        print(f\"\\n  n={n} (sample size {n_idx+1}/{len(all_sample_sizes)}):\")\n",
    "        sample_start_time = time.perf_counter()\n",
    "        \n",
    "        for rep in range(n_reps):\n",
    "            rep_seed = seeds[(n, rep)]\n",
    "            \n",
    "            # Generate data\n",
    "            data_rng = np.random.default_rng(rep_seed)\n",
    "            X, y, beta_true, _ = generate_data(n, p, model, distribution, sigma, data_rng)\n",
    "            \n",
    "            # Run each method\n",
    "            for method_name, method_code in methods_for_n:\n",
    "                opt_rng = np.random.default_rng(rep_seed + 1)\n",
    "                \n",
    "                t0 = time.perf_counter()\n",
    "                d_est, beta_est, h_est, cv, cv_path, min_time, min_count, min_iters = search_dimension_single(\n",
    "                    X, y, max_d=max_d, degree=degree,\n",
    "                    kernel_order=kernel_order, method=method_code,\n",
    "                    n_restarts=n_restarts, rng=opt_rng,\n",
    "                    model=model\n",
    "                )\n",
    "                t = time.perf_counter() - t0\n",
    "                \n",
    "                res = method_results[method_name]\n",
    "                err = subspace_distance(beta_true, beta_est)\n",
    "                \n",
    "                # Always record time, subspace error, and minimize stats\n",
    "                res['times_all'].append(t)\n",
    "                res['subspace_errors_all'].append(err)\n",
    "                res['minimize_times_all'].append(min_time)\n",
    "                res['minimize_counts_all'].append(min_count)\n",
    "                res['minimize_iters_all'].append(min_iters)\n",
    "                \n",
    "                # Record separately when dimension is correct\n",
    "                if d_est == d_true:\n",
    "                    res['d_correct'] += 1\n",
    "                    res['times_correct'].append(t)\n",
    "                    res['subspace_errors'].append(err)\n",
    "                    res['minimize_times_correct'].append(min_time)\n",
    "                    res['minimize_counts_correct'].append(min_count)\n",
    "                    res['minimize_iters_correct'].append(min_iters)\n",
    "            \n",
    "            # Progress logging\n",
    "            if (rep + 1) % 10 == 0 or rep == n_reps - 1:\n",
    "                elapsed = time.perf_counter() - sample_start_time\n",
    "                avg_per_rep = elapsed / (rep + 1)\n",
    "                remaining_reps = n_reps - (rep + 1)\n",
    "                eta_seconds = avg_per_rep * remaining_reps\n",
    "                eta_min = eta_seconds / 60\n",
    "                \n",
    "                total_elapsed = time.perf_counter() - total_start_time\n",
    "                total_elapsed_min = total_elapsed / 60\n",
    "                \n",
    "                print(f\"    Rep {rep+1}/{n_reps} | Elapsed: {elapsed:.1f}s | ETA for n={n}: {eta_min:.1f}min | Total elapsed: {total_elapsed_min:.1f}min\", flush=True)\n",
    "        \n",
    "        # Print summaries\n",
    "        for method_name in method_results:\n",
    "            res = method_results[method_name]\n",
    "            d_correct = res['d_correct']\n",
    "            times_all = res['times_all']\n",
    "            times_correct = res['times_correct']\n",
    "            subspace_errors_all = res['subspace_errors_all']\n",
    "            subspace_errors = res['subspace_errors']\n",
    "            minimize_times_all = res['minimize_times_all']\n",
    "            minimize_times_correct = res['minimize_times_correct']\n",
    "            minimize_counts_all = res['minimize_counts_all']\n",
    "            minimize_counts_correct = res['minimize_counts_correct']\n",
    "            minimize_iters_all = res['minimize_iters_all']\n",
    "            minimize_iters_correct = res['minimize_iters_correct']\n",
    "            \n",
    "            print(f\"    {method_name}: Dim acc {d_correct}/{n_reps} ({100*d_correct/n_reps:.0f}%)\", end=\"\")\n",
    "            \n",
    "            # Print \"when correct\" metrics\n",
    "            if times_correct:\n",
    "                se_time = np.std(times_correct) / np.sqrt(len(times_correct))\n",
    "                print(f\", Time(corr) {np.mean(times_correct):.2f}±{se_time:.2f}s\", end=\"\")\n",
    "            if subspace_errors:\n",
    "                se_suberr = np.std(subspace_errors) / np.sqrt(len(subspace_errors))\n",
    "                print(f\", SubErr(corr) {np.mean(subspace_errors):.4f}±{se_suberr:.4f}\", end=\"\")\n",
    "            if minimize_times_correct and minimize_counts_correct:\n",
    "                avg_min_time_corr = [t/c if c > 0 else 0 for t, c in zip(minimize_times_correct, minimize_counts_correct)]\n",
    "                se_min_time_corr = np.std(avg_min_time_corr) / np.sqrt(len(avg_min_time_corr))\n",
    "                print(f\", MinTime(corr) {np.mean(avg_min_time_corr):.4f}±{se_min_time_corr:.4f}s\", end=\"\")\n",
    "            if minimize_iters_correct and minimize_counts_correct:\n",
    "                avg_min_iters_corr = [i/c if c > 0 else 0 for i, c in zip(minimize_iters_correct, minimize_counts_correct)]\n",
    "                se_min_iters_corr = np.std(avg_min_iters_corr) / np.sqrt(len(avg_min_iters_corr))\n",
    "                print(f\", MinIters(corr) {np.mean(avg_min_iters_corr):.1f}±{se_min_iters_corr:.1f}\", end=\"\")\n",
    "            if minimize_times_correct and minimize_iters_correct:\n",
    "                time_per_iter_corr = [t/i if i > 0 else 0 for t, i in zip(minimize_times_correct, minimize_iters_correct)]\n",
    "                se_time_per_iter_corr = np.std(time_per_iter_corr) / np.sqrt(len(time_per_iter_corr))\n",
    "                print(f\", TimePerIter(corr) {np.mean(time_per_iter_corr)*1000:.2f}±{se_time_per_iter_corr*1000:.2f}ms\", end=\"\")\n",
    "            \n",
    "            # Print \"all\" metrics\n",
    "            if times_all:\n",
    "                se_time_all = np.std(times_all) / np.sqrt(len(times_all))\n",
    "                print(f\", Time(all) {np.mean(times_all):.2f}±{se_time_all:.2f}s\", end=\"\")\n",
    "            if subspace_errors_all:\n",
    "                se_suberr_all = np.std(subspace_errors_all) / np.sqrt(len(subspace_errors_all))\n",
    "                print(f\", SubErr(all) {np.mean(subspace_errors_all):.4f}±{se_suberr_all:.4f}\", end=\"\")\n",
    "            if minimize_times_all and minimize_counts_all:\n",
    "                avg_min_time_all = [t/c if c > 0 else 0 for t, c in zip(minimize_times_all, minimize_counts_all)]\n",
    "                se_min_time_all = np.std(avg_min_time_all) / np.sqrt(len(avg_min_time_all))\n",
    "                print(f\", MinTime(all) {np.mean(avg_min_time_all):.4f}±{se_min_time_all:.4f}s\", end=\"\")\n",
    "            if minimize_iters_all and minimize_counts_all:\n",
    "                avg_min_iters_all = [i/c if c > 0 else 0 for i, c in zip(minimize_iters_all, minimize_counts_all)]\n",
    "                se_min_iters_all = np.std(avg_min_iters_all) / np.sqrt(len(avg_min_iters_all))\n",
    "                print(f\", MinIters(all) {np.mean(avg_min_iters_all):.1f}±{se_min_iters_all:.1f}\", end=\"\")\n",
    "            if minimize_times_all and minimize_iters_all:\n",
    "                time_per_iter_all = [t/i if i > 0 else 0 for t, i in zip(minimize_times_all, minimize_iters_all)]\n",
    "                se_time_per_iter_all = np.std(time_per_iter_all) / np.sqrt(len(time_per_iter_all))\n",
    "                print(f\", TimePerIter(all) {np.mean(time_per_iter_all)*1000:.2f}±{se_time_per_iter_all*1000:.2f}ms\", end=\"\")\n",
    "            print()\n",
    "            \n",
    "            # Compute avg minimize time and iterations per call\n",
    "            avg_min_time_corr = [t/c if c > 0 else 0 for t, c in zip(minimize_times_correct, minimize_counts_correct)] if minimize_times_correct else []\n",
    "            avg_min_time_all = [t/c if c > 0 else 0 for t, c in zip(minimize_times_all, minimize_counts_all)] if minimize_times_all else []\n",
    "            avg_min_iters_corr = [i/c if c > 0 else 0 for i, c in zip(minimize_iters_correct, minimize_counts_correct)] if minimize_iters_correct else []\n",
    "            avg_min_iters_all = [i/c if c > 0 else 0 for i, c in zip(minimize_iters_all, minimize_counts_all)] if minimize_iters_all else []\n",
    "            # Compute time per iteration (total time / total iters for each rep)\n",
    "            time_per_iter_corr = [t/i if i > 0 else 0 for t, i in zip(minimize_times_correct, minimize_iters_correct)] if minimize_times_correct else []\n",
    "            time_per_iter_all = [t/i if i > 0 else 0 for t, i in zip(minimize_times_all, minimize_iters_all)] if minimize_times_all else []\n",
    "            \n",
    "            # Store result\n",
    "            results.append({\n",
    "                'Method': method_name,\n",
    "                'Model': model,\n",
    "                'X_dist': distribution,\n",
    "                'n': n,\n",
    "                'n_reps': n_reps,\n",
    "                'd_true': d_true,\n",
    "                'n_correct': d_correct,\n",
    "                'dim_accuracy': d_correct / n_reps,\n",
    "                # Metrics when dimension correct\n",
    "                'time_mean': np.mean(times_correct) if times_correct else np.nan,\n",
    "                'time_std': np.std(times_correct) / np.sqrt(len(times_correct)) if times_correct else np.nan,\n",
    "                'subspace_error_mean': np.mean(subspace_errors) if subspace_errors else np.nan,\n",
    "                'subspace_error_std': np.std(subspace_errors) / np.sqrt(len(subspace_errors)) if subspace_errors else np.nan,\n",
    "                'minimize_time_mean': np.mean(avg_min_time_corr) if avg_min_time_corr else np.nan,\n",
    "                'minimize_time_std': np.std(avg_min_time_corr) / np.sqrt(len(avg_min_time_corr)) if avg_min_time_corr else np.nan,\n",
    "                'minimize_iters_mean': np.mean(avg_min_iters_corr) if avg_min_iters_corr else np.nan,\n",
    "                'minimize_iters_std': np.std(avg_min_iters_corr) / np.sqrt(len(avg_min_iters_corr)) if avg_min_iters_corr else np.nan,\n",
    "                'time_per_iter_mean': np.mean(time_per_iter_corr) if time_per_iter_corr else np.nan,\n",
    "                'time_per_iter_std': np.std(time_per_iter_corr) / np.sqrt(len(time_per_iter_corr)) if time_per_iter_corr else np.nan,\n",
    "                # Metrics for all runs\n",
    "                'time_all_mean': np.mean(times_all) if times_all else np.nan,\n",
    "                'time_all_std': np.std(times_all) / np.sqrt(len(times_all)) if times_all else np.nan,\n",
    "                'subspace_error_all_mean': np.mean(subspace_errors_all) if subspace_errors_all else np.nan,\n",
    "                'subspace_error_all_std': np.std(subspace_errors_all) / np.sqrt(len(subspace_errors_all)) if subspace_errors_all else np.nan,\n",
    "                'minimize_time_all_mean': np.mean(avg_min_time_all) if avg_min_time_all else np.nan,\n",
    "                'minimize_time_all_std': np.std(avg_min_time_all) / np.sqrt(len(avg_min_time_all)) if avg_min_time_all else np.nan,\n",
    "                'minimize_iters_all_mean': np.mean(avg_min_iters_all) if avg_min_iters_all else np.nan,\n",
    "                'minimize_iters_all_std': np.std(avg_min_iters_all) / np.sqrt(len(avg_min_iters_all)) if avg_min_iters_all else np.nan,\n",
    "                'time_per_iter_all_mean': np.mean(time_per_iter_all) if time_per_iter_all else np.nan,\n",
    "                'time_per_iter_all_std': np.std(time_per_iter_all) / np.sqrt(len(time_per_iter_all)) if time_per_iter_all else np.nan,\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    column_order = ['Method', 'Model', 'X_dist', 'n', 'n_reps', 'd_true', 'n_correct',\n",
    "                    'dim_accuracy', \n",
    "                    'time_mean', 'time_std', \n",
    "                    'subspace_error_mean', 'subspace_error_std',\n",
    "                    'minimize_time_mean', 'minimize_time_std',\n",
    "                    'minimize_iters_mean', 'minimize_iters_std',\n",
    "                    'time_per_iter_mean', 'time_per_iter_std',\n",
    "                    'time_all_mean', 'time_all_std',\n",
    "                    'subspace_error_all_mean', 'subspace_error_all_std',\n",
    "                    'minimize_time_all_mean', 'minimize_time_all_std',\n",
    "                    'minimize_iters_all_mean', 'minimize_iters_all_std',\n",
    "                    'time_per_iter_all_mean', 'time_per_iter_all_std']\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Save to file\n",
    "    if output_file:\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nResults saved to '{output_file}'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "#### Minimal call for local experimenting\n",
    "\n",
    "def run_experiments(\n",
    "    models=['M1', 'M2', 'M3_func1', 'M3_func2'],\n",
    "    sample_sizes=[50, 100, 400, 1000, 2000, 5000],\n",
    "    p_values=[5, 10],\n",
    "    distributions=['uniform', 'normal'],\n",
    "    methods=['hat', 'nw'],\n",
    "    n_reps=100,\n",
    "    global_seed=42,\n",
    "    output_file='results.csv'\n",
    "):\n",
    "    \"\"\"\n",
    "    Run experiments across multiple configurations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list\n",
    "        Models to test, e.g. ['M1', 'M2', 'M3_func1', 'M3_func2']\n",
    "    sample_sizes : list\n",
    "        Sample sizes to test, e.g. [50, 100, 400, 1000] or just [100]\n",
    "    p_values : list\n",
    "        Number of predictors, e.g. [5, 10]\n",
    "    distributions : list\n",
    "        X distributions, e.g. ['uniform', 'normal']\n",
    "    methods : list\n",
    "        Methods to run, e.g. ['hat', 'nw'] or ['hat'] or ['nw']\n",
    "    n_reps : int\n",
    "        Number of replications per configuration\n",
    "    global_seed : int\n",
    "        Random seed\n",
    "    output_file : str or None\n",
    "        CSV filename to save combined results (None to skip saving)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        Combined results for all configurations\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # Determine method parameter for run_experiment_single\n",
    "    if set(methods) == {'hat', 'nw'}:\n",
    "        method_arg = 'all'\n",
    "    elif 'hat' in methods:\n",
    "        method_arg = 'hat'\n",
    "    elif 'nw' in methods:\n",
    "        method_arg = 'nw'\n",
    "    else:\n",
    "        raise ValueError(\"methods must contain 'hat' and/or 'nw'\")\n",
    "    \n",
    "    # Iterate over all configurations\n",
    "    for model in models:\n",
    "        for distribution in distributions:\n",
    "            for p in p_values:\n",
    "                for n in sample_sizes:  # Loop over each sample size\n",
    "                    # Set sigma based on model\n",
    "                    sigma = 2.0 if model == 'M3_func2' else 0.2\n",
    "                    \n",
    "                    # Run experiment for this specific configuration\n",
    "                    df = run_experiment_single(\n",
    "                        model=model,\n",
    "                        distribution=distribution,\n",
    "                        n_reps=n_reps,\n",
    "                        p=p,\n",
    "                        sigma=sigma,\n",
    "                        global_seed=global_seed,\n",
    "                        output_file=None,\n",
    "                        method=method_arg,\n",
    "                        sample_size=n  # Run only this sample size\n",
    "                    )\n",
    "                    \n",
    "                    # Add p column\n",
    "                    df.insert(4, 'p', p)\n",
    "                    \n",
    "                    all_results.append(df)\n",
    "    \n",
    "    # Combine all results\n",
    "    combined_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Reorder columns\n",
    "    column_order = ['Method', 'Model', 'X_dist', 'p', 'n', 'n_reps', 'd_true', 'n_correct',\n",
    "                    'dim_accuracy', \n",
    "                    'time_mean', 'time_std', \n",
    "                    'subspace_error_mean', 'subspace_error_std',\n",
    "                    'minimize_time_mean', 'minimize_time_std',\n",
    "                    'minimize_iters_mean', 'minimize_iters_std',\n",
    "                    'time_per_iter_mean', 'time_per_iter_std',\n",
    "                    'time_all_mean', 'time_all_std',\n",
    "                    'subspace_error_all_mean', 'subspace_error_all_std',\n",
    "                    'minimize_time_all_mean', 'minimize_time_all_std',\n",
    "                    'minimize_iters_all_mean', 'minimize_iters_all_std',\n",
    "                    'time_per_iter_all_mean', 'time_per_iter_all_std']\n",
    "    combined_df = combined_df[column_order]\n",
    "    \n",
    "    # Save combined results\n",
    "    if output_file:\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nAll results saved to '{output_file}'\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# Example: Quick test with minimal configuration\n",
    "df = run_experiments(\n",
    "    models=['M1'],\n",
    "    sample_sizes=[100],\n",
    "    p_values=[5],\n",
    "    distributions=['uniform'],\n",
    "    methods=['hat', 'nw'], # hat is our method, nw is Huang and Chiang (2016)\n",
    "    n_reps=1,\n",
    "    output_file='quick_test.csv'\n",
    ")\n",
    "\n",
    "#### Below is for command-line execution (used for ALICE cluster experiments)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(description='Run dimension reduction experiments')\n",
    "#     parser.add_argument('--model', type=str, required=True,\n",
    "#                        choices=['M1', 'M2', 'M3_func1', 'M3_func2'],\n",
    "#                        help='Model to run')\n",
    "#     parser.add_argument('--distribution', type=str, required=True,\n",
    "#                        choices=['uniform', 'normal'],\n",
    "#                        help='Distribution for X')\n",
    "#     parser.add_argument('--method', type=str, default='all',\n",
    "#                        choices=['hat', 'nw', 'all'],\n",
    "#                        help='Method to run')\n",
    "#     parser.add_argument('--sample_size', type=int, default=None,\n",
    "#                        help='Single sample size to run (default: all)')\n",
    "#     parser.add_argument('--n_reps', type=int, default=100,\n",
    "#                        help='Number of replications')\n",
    "#     parser.add_argument('--p', type=int, default=10,\n",
    "#                        help='Number of predictors')\n",
    "#     parser.add_argument('--seed', type=int, default=42,\n",
    "#                        help='Global random seed')\n",
    "#     parser.add_argument('--output', type=str, default=None,\n",
    "#                        help='Output CSV file')\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     # Set sigma based on model\n",
    "#     sigma = 2.0 if args.model == 'M3_func2' else 0.2\n",
    "    \n",
    "#     df = run_experiment_single(\n",
    "#         model=args.model,\n",
    "#         distribution=args.distribution,\n",
    "#         n_reps=args.n_reps,\n",
    "#         p=args.p,\n",
    "#         sigma=sigma,\n",
    "#         global_seed=args.seed,\n",
    "#         output_file=args.output,\n",
    "#         method=args.method,\n",
    "#         sample_size=args.sample_size\n",
    "#     )\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"COMPLETED\")\n",
    "#     print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a04a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
